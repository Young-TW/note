# 進度統整

使用 gpt-oss-20b 或是 Llama-3.1-8B-Instruct 時，vLLM 出現錯誤訊息如下：

```sh
lmcache_producer  | (EngineCore_DP0 pid=719) [2026-01-08 16:41:10,987] LMCache WARNING: batched put error: zip() argument 2 is shorter than argument 1 (instrumented_connector.py:118:lmcache.v1.storage_backend.connector.instrumented_connector)
```

改用 Llama-4-Scout-17B-16E-Instruct 後，vLLM 出現錯誤訊息如下：

```sh
lmcache_producer  | (EngineCore_DP0 pid=726) [2026-01-12 02:29:01,448] LMCache ERROR: Failed to write file /dev/shm/lmcache_store/vllm@-SEP-app-SEP-model-SEP-Llama-3.1-8B-Instruct@1@0@-4777b4c6f9fa4ac2@bfloat16.data: zip() argument 2 is shorter than argument 1 (fs_connector.py:342:lmcache.v1.storage_backend.connector.fs_connector)
```
