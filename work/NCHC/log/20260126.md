# 進度統整

以下是 LMcache 使用 Llama-3.3-70B-Instruct 和 gpt-oss-120b 模型，多個 instance，每個 instance 使用 1 GPU 的情況下，測試 TTFT（Two-Stage Token Fetching）和 TPS（Two-Phase Scheduling）兩種不同的加速策略的結果。

圖表中包含了 TP1、TP2、TP4、TP8 等不同的模型並行數量，作為比較基準。

